---
pinned: true
published: true
title: Python for the Real World
slug: production-python-tips
date: 2025-04-25
cover: images/python_snake.jpg
category: Build Log
excerpt: "Tips, habits, and hard-won lessons for writing Python that's maintainable and understandable."
---

Python gets a lot of things right, but it also makes it easy to write code that works locally and breaks mysteriously in production. I've learned this through some painful debugging sessions and a few too many late-night deployments.

The patterns here aren't about writing perfect code - they're about writing code that fails predictably, debugs easily, and doesn't surprise your teammates. Most of these lessons came from building systems at scale, where small oversights become big problems fast.

# Setting Up for Success

Before diving into code patterns, let's talk about the tools that actually matter. I've seen too many teams spend weeks configuring complex toolchains or waiting for slow package installs when they could be shipping features instead.

## The Toolchain That Actually Works

After years of juggling multiple formatters, linters, and package managers, I've settled on two tools that solve most problems: Ruff for code quality and UV for package management.

**Why this matters:** Slow, unreliable tooling kills productivity. When running linters takes 10+ seconds, people skip them. When package installation is unpredictable, deployments break randomly.

Ruff replaced my entire formatting and linting pipeline. Where I used to run 4-5 different tools, now it's just one:

```bash
# Old way: 8+ seconds of waiting
black . && isort . && flake8 && bandit -r .

# New way: 0.2 seconds
ruff format . && ruff check --fix .
```

UV solved my package management headaches. No more `pip install` hanging, no more forgetting to activate virtual environments:

```bash
# Everything in one tool
uv init myproject && cd myproject
uv add fastapi sqlalchemy  # Installs + creates venv automatically
uv run python main.py      # Runs in correct environment
```

The configuration is minimal but covers the important stuff - style consistency, common bugs, and security issues. Not because I love rules, but because I've debugged too many problems that these tools would have caught.

# Making Your Code Reliable

I used to think type hints were just documentation. Then I spent a weekend debugging a production issue that would have been caught by a type checker in 10 seconds. Now I consider modern Python without type hints like driving without seatbelts.

**Why this matters:** The most expensive bugs are the ones that reach production. Type hints catch entire categories of errors before your code ever runs, and they make refactoring confident instead of terrifying.

## The Safety Net That Actually Works

Type hints aren't about being pedantic - they're about preventing the kind of mistakes that cause 2 AM debugging sessions. Start simple:

```python
# Your function signature becomes documentation
def retry_request(url: str, max_attempts: int = 3, timeout: float = 5.0) -> dict:
    # Your IDE now knows exactly what this function expects and returns
    pass

# Prevent magic string typos before they become runtime errors
from typing import Literal
LogLevel = Literal["debug", "info", "warning", "error"]

def log(message: str, level: LogLevel = "info") -> None:
    print(f"[{level.upper()}] {message}")
    # log("Hello", "infoo") <- Type checker catches this typo
```

For more complex scenarios, Protocols let you define interfaces based on behavior rather than inheritance - perfect for Python's duck typing:

```python
from typing import Protocol

class Drawable(Protocol):
    def draw(self) -> str: ...

# Any object with a draw() method works - no inheritance needed
def render(obj: Drawable) -> str:
    return obj.draw()
```

Set up [mypy](http://mypy-lang.org/) in strict mode and add it to your CI pipeline. It's like having a vigilant code reviewer who never gets tired:

```bash
uv add --dev mypy
uv run mypy src/  # Add this to your CI
```

## Stop Writing Boilerplate

I used to write classes with 15+ lines of `__init__`, `__repr__`, and `__eq__` methods. Then I discovered dataclasses and realized I was wasting time on code that could be generated automatically.

Dataclasses handle the tedious stuff so you can focus on business logic:

```python
from dataclasses import dataclass, field
import time

@dataclass
class User:
    name: str
    email: str
    tags: list[str] = field(default_factory=list)  # Safe mutable defaults
    created_at: float = field(default_factory=time.time)

    def __post_init__(self) -> None:  # Custom validation
        if "@" not in self.email:
            raise ValueError(f"Invalid email: {self.email}")

# Gets __init__, __repr__, __eq__, and more for free
user = User("Alice", "alice@example.com")
print(user)  # Clean string representation automatically
```

This isn't just about saving typing - the generated methods are usually better than what most people write manually, and they handle edge cases consistently.

## Understanding Performance Reality

Everyone talks about Python being slow, but in a decade of production Python, I've rarely encountered situations where language speed was the bottleneck. Network calls, database queries, and file I/O dominate most applications.

**The GIL truth:** Python's Global Interpreter Lock prevents true CPU parallelism, but most code is I/O-bound anyway. Threading works perfectly for network requests, database calls, and file operations because the GIL releases during system calls.

**Async reality check:** Don't rewrite everything for async just because it's fashionable. I once spent months converting a data pipeline to async, thinking it would solve performance issues. The real bottleneck was CPU-bound processing, not I/O.

But when async helps, the improvement is dramatic:

```python
# An API aggregating 20 services went from 30-second timeouts to sub-second
async def fetch_all(urls):
    async with aiohttp.ClientSession() as session:
        tasks = [session.get(url) for url in urls]
        responses = await asyncio.gather(*tasks)
        return [await r.json() for r in responses]
```

**Simple rule:** Use async for I/O-heavy work with lots of waiting. Skip it for CPU-bound work, simple scripts, or anything with sync-only libraries. Profile before you optimize - the bottleneck is rarely where you think it is.

## Don't Guess at Performance

I once spent three weeks "optimizing" code that ran once a day and took 2 seconds. Meanwhile, a function called thousands of times per second was using a list for lookups instead of a set. Profile first, optimize second:

```python
# Often the fix is embarrassingly simple
if user_id in user_list:  # O(n) - slow
if user_id in user_set:   # O(1) - fast
```

Use Python's built-in profiler to find the real bottlenecks:

```bash
python -m cProfile -o profile.stats your_script.py
pip install snakeviz && snakeviz profile.stats
```

Usually the solution is basic: `@lru_cache` on expensive functions, generators instead of lists for large datasets, or choosing the right data structure.

## Handle Errors Like a Professional

Generic exceptions are debugging nightmares. When your code throws `Exception: Something went wrong`, good luck figuring out whether to retry, fail fast, or schedule a cleanup task.

Build exception hierarchies that let callers handle different failure modes intelligently:

```python
class APIError(Exception):
    pass

class RateLimitError(APIError):
    def __init__(self, message: str, retry_after: int):
        super().__init__(message)
        self.retry_after = retry_after

# Now callers can make smart decisions
try:
    call_api()
except RateLimitError as e:
    schedule_retry(e.retry_after)  # Specific handling
except APIError:
    mark_service_down()            # General API failure
```

**Logging that actually helps:** Use the right log levels - DEBUG for diagnostics you don't usually need, INFO for normal operations, WARNING for things that might become problems, ERROR for actual failures. Future you will thank you when debugging at 2 AM.

## Configuration That Doesn't Break

I've debugged too many production issues that boiled down to a hardcoded URL or a missing environment variable. The worst ones fail silently until something important breaks.

Type and validate your configuration upfront:

```python
from pydantic import BaseSettings

class Settings(BaseSettings):
    database_url: str  # Required - fails fast if missing
    debug: bool = False
    max_workers: int = 4

    class Config:
        env_file = ".env"

settings = Settings()  # Validates on startup, not at runtime
```

Now if someone forgets to set `DATABASE_URL`, the application fails immediately with a clear error instead of mysteriously breaking later.

## Managing Resources and Cross-Cutting Concerns

Python's context managers and decorators solve two common problems: ensuring cleanup happens even when things go wrong, and avoiding repetitive code patterns.

**Context managers guarantee cleanup:** Even if an exception occurs, resources get cleaned up properly. Essential for database connections, file handles, and temporary states:

```python
from contextlib import contextmanager

@contextmanager
def timer(description):
    start = time.time()
    try:
        yield
    finally:
        print(f"{description}: {time.time() - start:.3f}s")

with timer("Database query"):
    expensive_operation()  # Always get timing, even if it crashes
```

**Decorators eliminate repetition:** Instead of copy-pasting retry logic everywhere, write it once and reuse it:

```python
def retry(max_attempts=3):
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_attempts):
                try:
                    return func(*args, **kwargs)
                except Exception:
                    if attempt == max_attempts - 1:
                        raise
                    time.sleep(2 ** attempt)
        return wrapper
    return decorator

@retry(max_attempts=3)
def unreliable_api_call():
    pass  # Automatically retries with exponential backoff
```

## Testing That Actually Works

Testing shouldn't be a chore. Pytest makes it straightforward to write tests that catch bugs without getting in your way.

**Test multiple scenarios cleanly:**

```python
import pytest

@pytest.mark.parametrize("email,valid", [
    ("alice@example.com", True),
    ("invalid-email", False),
])
def test_email_validation(email, valid):
    if valid:
        user = User("Alice", email)
        assert user.email == email
    else:
        with pytest.raises(ValueError):
            User("Alice", email)
```

**Mock external dependencies:** Don't hit real APIs or databases in tests. Mock them so tests run fast and don't depend on external services:

```python
from unittest.mock import patch, Mock

@patch('requests.get')
def test_retry_logic(mock_get):
    mock_get.side_effect = [
        Mock(status_code=500),  # First call fails
        Mock(status_code=200, json=lambda: {"data": "success"})
    ]

    result = fetch_with_retry("https://api.example.com")
    assert result["data"] == "success"
    assert mock_get.call_count == 2  # Verify it retried
```

# Patterns That Actually Matter

After years of writing Python, these are the patterns that consistently save time and prevent bugs. They're not fancy - they're just effective.

## Use the Standard Library's Hidden Powers

Python's standard library contains solutions to most common problems. Instead of writing custom loops and logic, learn to leverage these tools:

**Why this matters:** These modules are implemented in C, handle edge cases you haven't thought of, and clearly communicate intent. The performance boost with large datasets can be significant.

```python
from itertools import groupby, chain
from operator import itemgetter
from functools import partial
import bisect

# Group consecutive items (perfect for processing logs)
data = [1, 1, 2, 2, 2, 3]
for key, group in groupby(data):
    print(f"{key}: {len(list(group))}")

# Sort by specific field (faster than lambda)
users = [('Alice', 25), ('Bob', 30)]
sorted_users = sorted(users, key=itemgetter(1))

# Maintain sorted collections efficiently
sorted_scores = [60, 70, 80, 90]
bisect.insort(sorted_scores, 75)  # O(log n) insertion

# Pre-configure functions cleanly
log_error = partial(print, "[ERROR]", file=sys.stderr)
```

## Make Your Objects Feel Native

Implementing Python's "magic methods" makes your classes behave like built-in types. The payoff is intuitive, readable code:

```python
class Vector:
    def __init__(self, x: float, y: float):
        self.x, self.y = x, y

    def __add__(self, other: 'Vector') -> 'Vector':
        return Vector(self.x + other.x, self.y + other.y)

    def __repr__(self) -> str:
        return f"Vector({self.x}, {self.y})"

# Now it feels natural
v1 = Vector(1, 2)
v2 = Vector(3, 4)
result = v1 + v2  # Immediately understandable
```

When someone reads `v1 + v2`, they instantly understand what's happening. That's the difference between library code and language-level code.

## Handle Multiline Strings Properly

Multiline strings inside functions pick up unwanted indentation from your code. `textwrap.dedent` fixes this:

```python
import textwrap

def generate_email():
    return textwrap.dedent("""
        Dear User,

        Your account has been updated.
        Please log in to verify.

        Best regards,
        The Team
    """).strip()
```

Essential for SQL queries, email templates, and any text that needs to look clean when output.

# Why This Actually Matters

I'm not trying to be comprehensive here. Python's ecosystem is huge and there are dozens of other tools and patterns worth knowing. But these are the ones that consistently save me time and prevent 2 AM debugging sessions.

The goal isn't to use every technique - it's to write code that works reliably and can be maintained by humans (including future you). Sometimes that means fancy async patterns, sometimes it just means using a `set()` instead of a `list`.

Pick what fits your problems, ignore the rest, and remember that working code shipped is better than perfect code that never leaves your laptop.
